{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available!  Training on GPU ...\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Epoch = 1 | loss = 2.5475\n",
      "acc = 0.113\n",
      "Epoch = 2 | loss = 2.2827\n",
      "acc = 0.115\n",
      "Epoch = 3 | loss = 2.2759\n",
      "acc = 0.130\n",
      "Epoch = 4 | loss = 2.0480\n",
      "acc = 0.254\n",
      "Epoch = 5 | loss = 1.7250\n",
      "acc = 0.376\n",
      "Epoch = 6 | loss = 1.4172\n",
      "acc = 0.547\n",
      "Epoch = 7 | loss = 1.1246\n",
      "acc = 0.654\n",
      "Epoch = 8 | loss = 0.9400\n",
      "acc = 0.693\n",
      "Epoch = 9 | loss = 0.8232\n",
      "acc = 0.721\n",
      "Epoch = 10 | loss = 0.7495\n",
      "acc = 0.745\n",
      "Epoch = 11 | loss = 0.6979\n",
      "acc = 0.772\n",
      "Epoch = 12 | loss = 0.6562\n",
      "acc = 0.770\n",
      "Epoch = 13 | loss = 0.6165\n",
      "acc = 0.794\n",
      "Epoch = 14 | loss = 0.5913\n",
      "acc = 0.780\n",
      "Epoch = 15 | loss = 0.5747\n",
      "acc = 0.800\n",
      "Epoch = 16 | loss = 0.5609\n",
      "acc = 0.806\n",
      "Epoch = 17 | loss = 0.5490\n",
      "acc = 0.798\n",
      "Epoch = 18 | loss = 0.5303\n",
      "acc = 0.816\n",
      "Epoch = 19 | loss = 0.5139\n",
      "acc = 0.792\n",
      "Epoch = 20 | loss = 0.5089\n",
      "acc = 0.812\n",
      "Epoch = 21 | loss = 0.5027\n",
      "acc = 0.831\n",
      "Epoch = 22 | loss = 0.4858\n",
      "acc = 0.818\n",
      "Epoch = 23 | loss = 0.4814\n",
      "acc = 0.819\n",
      "Epoch = 24 | loss = 0.4790\n",
      "acc = 0.824\n",
      "Epoch = 25 | loss = 0.4702\n",
      "acc = 0.818\n",
      "Epoch = 26 | loss = 0.4634\n",
      "acc = 0.822\n",
      "Epoch = 27 | loss = 0.4557\n",
      "acc = 0.827\n",
      "Epoch = 28 | loss = 0.4589\n",
      "acc = 0.834\n",
      "Epoch = 29 | loss = 0.4507\n",
      "acc = 0.834\n",
      "Epoch = 30 | loss = 0.4454\n",
      "acc = 0.828\n",
      "Epoch = 31 | loss = 0.4357\n",
      "acc = 0.818\n",
      "Epoch = 32 | loss = 0.4363\n",
      "acc = 0.827\n",
      "Epoch = 33 | loss = 0.4263\n",
      "acc = 0.834\n",
      "Epoch = 34 | loss = 0.4264\n",
      "acc = 0.843\n",
      "Epoch = 35 | loss = 0.4204\n",
      "acc = 0.830\n",
      "Epoch = 36 | loss = 0.4202\n",
      "acc = 0.843\n",
      "Epoch = 37 | loss = 0.4149\n",
      "acc = 0.836\n",
      "Epoch = 38 | loss = 0.4106\n",
      "acc = 0.836\n",
      "Epoch = 39 | loss = 0.4197\n",
      "acc = 0.843\n",
      "Epoch = 40 | loss = 0.4067\n",
      "acc = 0.849\n",
      "Epoch = 41 | loss = 0.4081\n",
      "acc = 0.845\n",
      "Epoch = 42 | loss = 0.3951\n",
      "acc = 0.847\n",
      "Epoch = 43 | loss = 0.3911\n",
      "acc = 0.838\n",
      "Epoch = 44 | loss = 0.3902\n",
      "acc = 0.843\n",
      "Epoch = 45 | loss = 0.3936\n",
      "acc = 0.839\n",
      "Epoch = 46 | loss = 0.3917\n",
      "acc = 0.842\n",
      "Epoch = 47 | loss = 0.3889\n",
      "acc = 0.852\n",
      "Epoch = 48 | loss = 0.3836\n",
      "acc = 0.855\n",
      "Epoch = 49 | loss = 0.3826\n",
      "acc = 0.853\n",
      "Epoch = 50 | loss = 0.3808\n",
      "acc = 0.844\n",
      "Epoch = 51 | loss = 0.3758\n",
      "acc = 0.859\n",
      "Epoch = 52 | loss = 0.3722\n",
      "acc = 0.844\n",
      "Epoch = 53 | loss = 0.3694\n",
      "acc = 0.850\n",
      "Epoch = 54 | loss = 0.3666\n",
      "acc = 0.855\n",
      "Epoch = 55 | loss = 0.3707\n",
      "acc = 0.852\n",
      "Epoch = 56 | loss = 0.3625\n",
      "acc = 0.851\n",
      "Epoch = 57 | loss = 0.3704\n",
      "acc = 0.843\n",
      "Epoch = 58 | loss = 0.3645\n",
      "acc = 0.856\n",
      "Epoch = 59 | loss = 0.3566\n",
      "acc = 0.860\n",
      "Epoch = 60 | loss = 0.3469\n",
      "acc = 0.854\n",
      "Epoch = 61 | loss = 0.3486\n",
      "acc = 0.864\n",
      "Epoch = 62 | loss = 0.3479\n",
      "acc = 0.861\n",
      "Epoch = 63 | loss = 0.3429\n",
      "acc = 0.851\n",
      "Epoch = 64 | loss = 0.3445\n",
      "acc = 0.848\n",
      "Epoch = 65 | loss = 0.3490\n",
      "acc = 0.850\n",
      "Epoch = 66 | loss = 0.3428\n",
      "acc = 0.847\n",
      "Epoch = 67 | loss = 0.3290\n",
      "acc = 0.864\n",
      "Epoch = 68 | loss = 0.3363\n",
      "acc = 0.863\n",
      "Epoch = 69 | loss = 0.3330\n",
      "acc = 0.850\n",
      "Epoch = 70 | loss = 0.3328\n",
      "acc = 0.859\n",
      "Epoch = 71 | loss = 0.3190\n",
      "acc = 0.860\n",
      "Epoch = 72 | loss = 0.3197\n",
      "acc = 0.860\n",
      "Epoch = 73 | loss = 0.3193\n",
      "acc = 0.859\n",
      "Epoch = 74 | loss = 0.3230\n",
      "acc = 0.855\n",
      "Epoch = 75 | loss = 0.3179\n",
      "acc = 0.859\n",
      "Epoch = 76 | loss = 0.3104\n",
      "acc = 0.864\n",
      "Epoch = 77 | loss = 0.3071\n",
      "acc = 0.856\n",
      "Epoch = 78 | loss = 0.3103\n",
      "acc = 0.853\n",
      "Epoch = 79 | loss = 0.3007\n",
      "acc = 0.867\n",
      "Epoch = 80 | loss = 0.3028\n",
      "acc = 0.859\n",
      "Epoch = 81 | loss = 0.2977\n",
      "acc = 0.863\n",
      "Epoch = 82 | loss = 0.2925\n",
      "acc = 0.856\n",
      "Epoch = 83 | loss = 0.3020\n",
      "acc = 0.868\n",
      "Epoch = 84 | loss = 0.2918\n",
      "acc = 0.876\n",
      "Epoch = 85 | loss = 0.2850\n",
      "acc = 0.866\n",
      "Epoch = 86 | loss = 0.2881\n",
      "acc = 0.868\n",
      "Epoch = 87 | loss = 0.2829\n",
      "acc = 0.869\n",
      "Epoch = 88 | loss = 0.2837\n",
      "acc = 0.865\n",
      "Epoch = 89 | loss = 0.2760\n",
      "acc = 0.865\n",
      "Epoch = 90 | loss = 0.2781\n",
      "acc = 0.880\n",
      "Epoch = 91 | loss = 0.2717\n",
      "acc = 0.876\n",
      "Epoch = 92 | loss = 0.2670\n",
      "acc = 0.880\n",
      "Epoch = 93 | loss = 0.2654\n",
      "acc = 0.861\n",
      "Epoch = 94 | loss = 0.2618\n",
      "acc = 0.877\n",
      "Epoch = 95 | loss = 0.2548\n",
      "acc = 0.867\n",
      "Epoch = 96 | loss = 0.2549\n",
      "acc = 0.871\n",
      "Epoch = 97 | loss = 0.2544\n",
      "acc = 0.879\n",
      "Epoch = 98 | loss = 0.2475\n",
      "acc = 0.875\n",
      "Epoch = 99 | loss = 0.2507\n",
      "acc = 0.872\n",
      "Epoch = 100 | loss = 0.2434\n",
      "acc = 0.881\n",
      "Epoch = 101 | loss = 0.2422\n",
      "acc = 0.873\n",
      "Epoch = 102 | loss = 0.2380\n",
      "acc = 0.875\n",
      "Epoch = 103 | loss = 0.2343\n",
      "acc = 0.879\n",
      "Epoch = 104 | loss = 0.2323\n",
      "acc = 0.884\n",
      "Epoch = 105 | loss = 0.2265\n",
      "acc = 0.878\n",
      "Epoch = 106 | loss = 0.2237\n",
      "acc = 0.878\n",
      "Epoch = 107 | loss = 0.2272\n",
      "acc = 0.871\n",
      "Epoch = 108 | loss = 0.2201\n",
      "acc = 0.885\n",
      "Epoch = 109 | loss = 0.2145\n",
      "acc = 0.881\n",
      "Epoch = 110 | loss = 0.2146\n",
      "acc = 0.875\n",
      "Epoch = 111 | loss = 0.2064\n",
      "acc = 0.887\n",
      "Epoch = 112 | loss = 0.2020\n",
      "acc = 0.887\n",
      "Epoch = 113 | loss = 0.1998\n",
      "acc = 0.884\n",
      "Epoch = 114 | loss = 0.1979\n",
      "acc = 0.883\n",
      "Epoch = 115 | loss = 0.1952\n",
      "acc = 0.885\n",
      "Epoch = 116 | loss = 0.1894\n",
      "acc = 0.881\n",
      "Epoch = 117 | loss = 0.1911\n",
      "acc = 0.888\n",
      "Epoch = 118 | loss = 0.1811\n",
      "acc = 0.881\n",
      "Epoch = 119 | loss = 0.1856\n",
      "acc = 0.886\n",
      "Epoch = 120 | loss = 0.1800\n",
      "acc = 0.892\n",
      "Epoch = 121 | loss = 0.1738\n",
      "acc = 0.889\n",
      "Epoch = 122 | loss = 0.1717\n",
      "acc = 0.887\n",
      "Epoch = 123 | loss = 0.1693\n",
      "acc = 0.885\n",
      "Epoch = 124 | loss = 0.1644\n",
      "acc = 0.896\n",
      "Epoch = 125 | loss = 0.1599\n",
      "acc = 0.891\n",
      "Epoch = 126 | loss = 0.1586\n",
      "acc = 0.896\n",
      "Epoch = 127 | loss = 0.1545\n",
      "acc = 0.887\n",
      "Epoch = 128 | loss = 0.1543\n",
      "acc = 0.892\n",
      "Epoch = 129 | loss = 0.1483\n",
      "acc = 0.893\n",
      "Epoch = 130 | loss = 0.1420\n",
      "acc = 0.892\n",
      "Epoch = 131 | loss = 0.1385\n",
      "acc = 0.892\n",
      "Epoch = 132 | loss = 0.1320\n",
      "acc = 0.895\n",
      "Epoch = 133 | loss = 0.1348\n",
      "acc = 0.898\n",
      "Epoch = 134 | loss = 0.1336\n",
      "acc = 0.899\n",
      "Epoch = 135 | loss = 0.1286\n",
      "acc = 0.897\n",
      "Epoch = 136 | loss = 0.1215\n",
      "acc = 0.897\n",
      "Epoch = 137 | loss = 0.1122\n",
      "acc = 0.898\n",
      "Epoch = 138 | loss = 0.1141\n",
      "acc = 0.899\n",
      "Epoch = 139 | loss = 0.1112\n",
      "acc = 0.896\n",
      "Epoch = 140 | loss = 0.1102\n",
      "acc = 0.896\n",
      "Epoch = 141 | loss = 0.1068\n",
      "acc = 0.901\n",
      "Epoch = 142 | loss = 0.0979\n",
      "acc = 0.902\n",
      "Epoch = 143 | loss = 0.0960\n",
      "acc = 0.902\n",
      "Epoch = 144 | loss = 0.0942\n",
      "acc = 0.902\n",
      "Epoch = 145 | loss = 0.0907\n",
      "acc = 0.904\n",
      "Epoch = 146 | loss = 0.0887\n",
      "acc = 0.905\n",
      "Epoch = 147 | loss = 0.0874\n",
      "acc = 0.897\n",
      "Epoch = 148 | loss = 0.0820\n",
      "acc = 0.904\n",
      "Epoch = 149 | loss = 0.0764\n",
      "acc = 0.902\n",
      "Epoch = 150 | loss = 0.0738\n",
      "acc = 0.902\n",
      "Epoch = 151 | loss = 0.0672\n",
      "acc = 0.900\n",
      "Epoch = 152 | loss = 0.0684\n",
      "acc = 0.907\n",
      "Epoch = 153 | loss = 0.0617\n",
      "acc = 0.905\n",
      "Epoch = 154 | loss = 0.0652\n",
      "acc = 0.910\n",
      "Epoch = 155 | loss = 0.0606\n",
      "acc = 0.908\n",
      "Epoch = 156 | loss = 0.0537\n",
      "acc = 0.905\n",
      "Epoch = 157 | loss = 0.0507\n",
      "acc = 0.908\n",
      "Epoch = 158 | loss = 0.0482\n",
      "acc = 0.915\n",
      "Epoch = 159 | loss = 0.0468\n",
      "acc = 0.907\n",
      "Epoch = 160 | loss = 0.0416\n",
      "acc = 0.915\n",
      "Epoch = 161 | loss = 0.0383\n",
      "acc = 0.914\n",
      "Epoch = 162 | loss = 0.0383\n",
      "acc = 0.913\n",
      "Epoch = 163 | loss = 0.0308\n",
      "acc = 0.913\n",
      "Epoch = 164 | loss = 0.0320\n",
      "acc = 0.914\n",
      "Epoch = 165 | loss = 0.0264\n",
      "acc = 0.913\n",
      "Epoch = 166 | loss = 0.0245\n",
      "acc = 0.916\n",
      "Epoch = 167 | loss = 0.0238\n",
      "acc = 0.917\n",
      "Epoch = 168 | loss = 0.0223\n",
      "acc = 0.923\n",
      "Epoch = 169 | loss = 0.0184\n",
      "acc = 0.920\n",
      "Epoch = 170 | loss = 0.0158\n",
      "acc = 0.919\n",
      "Epoch = 171 | loss = 0.0152\n",
      "acc = 0.925\n",
      "Epoch = 172 | loss = 0.0146\n",
      "acc = 0.925\n",
      "Epoch = 173 | loss = 0.0134\n",
      "acc = 0.923\n",
      "Epoch = 174 | loss = 0.0098\n",
      "acc = 0.925\n",
      "Epoch = 175 | loss = 0.0091\n",
      "acc = 0.923\n",
      "Epoch = 176 | loss = 0.0060\n",
      "acc = 0.926\n",
      "Epoch = 177 | loss = 0.0070\n",
      "acc = 0.928\n",
      "Epoch = 178 | loss = 0.0051\n",
      "acc = 0.926\n",
      "Epoch = 179 | loss = 0.0055\n",
      "acc = 0.927\n",
      "Epoch = 180 | loss = 0.0044\n",
      "acc = 0.929\n",
      "Epoch = 181 | loss = 0.0036\n",
      "acc = 0.929\n",
      "Epoch = 182 | loss = 0.0034\n",
      "acc = 0.932\n",
      "Epoch = 183 | loss = 0.0030\n",
      "acc = 0.928\n",
      "Epoch = 184 | loss = 0.0023\n",
      "acc = 0.930\n",
      "Epoch = 185 | loss = 0.0022\n",
      "acc = 0.928\n",
      "Epoch = 186 | loss = 0.0021\n",
      "acc = 0.933\n",
      "Epoch = 187 | loss = 0.0020\n",
      "acc = 0.930\n",
      "Epoch = 188 | loss = 0.0018\n",
      "acc = 0.932\n",
      "Epoch = 189 | loss = 0.0015\n",
      "acc = 0.934\n",
      "Epoch = 190 | loss = 0.0022\n",
      "acc = 0.930\n",
      "Epoch = 191 | loss = 0.0015\n",
      "acc = 0.932\n",
      "Epoch = 192 | loss = 0.0019\n",
      "acc = 0.932\n",
      "Epoch = 193 | loss = 0.0016\n",
      "acc = 0.934\n",
      "Epoch = 194 | loss = 0.0015\n",
      "acc = 0.933\n",
      "Epoch = 195 | loss = 0.0016\n",
      "acc = 0.932\n",
      "Epoch = 196 | loss = 0.0015\n",
      "acc = 0.935\n",
      "Epoch = 197 | loss = 0.0017\n",
      "acc = 0.934\n",
      "Epoch = 198 | loss = 0.0015\n",
      "acc = 0.934\n",
      "Epoch = 199 | loss = 0.0014\n",
      "acc = 0.934\n",
      "Epoch = 200 | loss = 0.0015\n",
      "acc = 0.934\n",
      "Finished Training\n",
      "Accuracy of the network on the 10000 test images: 93 %\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "\n",
    "train_on_gpu = torch.cuda.is_available()\n",
    "\n",
    "if not train_on_gpu:\n",
    "    print('CUDA is not available.  Training on CPU ...')\n",
    "else:\n",
    "    print('CUDA is available!  Training on GPU ...')\n",
    "\n",
    "def accuracy(model,testloader):\n",
    "    correct = 0 \n",
    "    total = 0\n",
    "    for data in testloader:\n",
    "            images, labels = data\n",
    "            if train_on_gpu:\n",
    "                images, labels = images.cuda(), labels.cuda()\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    print('acc = %.3f' %(correct/total))\n",
    "\n",
    "class CNN(nn.Module):  \n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv_layer = nn.Sequential(\n",
    "        nn.Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "        nn.BatchNorm2d(64),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.AvgPool2d(kernel_size=1, stride=1, padding=0),\n",
    "        nn.Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "        nn.BatchNorm2d(64),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.AvgPool2d(kernel_size=1, stride=1, padding=0),\n",
    "        nn.MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False),\n",
    "        nn.AvgPool2d(kernel_size=1, stride=1, padding=0),\n",
    "        nn.Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "        nn.BatchNorm2d(128),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.AvgPool2d(kernel_size=1, stride=1, padding=0),\n",
    "        nn.Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "        nn.BatchNorm2d(128),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.AvgPool2d(kernel_size=1, stride=1, padding=0),\n",
    "        nn.MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False),\n",
    "        nn.AvgPool2d(kernel_size=1, stride=1, padding=0),\n",
    "        nn.Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "        nn.BatchNorm2d(256),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.AvgPool2d(kernel_size=1, stride=1, padding=0),\n",
    "        nn.Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "        nn.BatchNorm2d(256),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.AvgPool2d(kernel_size=1, stride=1, padding=0),\n",
    "        nn.Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "        nn.BatchNorm2d(256),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.AvgPool2d(kernel_size=1, stride=1, padding=0),\n",
    "        nn.MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False),\n",
    "        nn.AvgPool2d(kernel_size=1, stride=1, padding=0),\n",
    "        nn.Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "        nn.BatchNorm2d(512),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.AvgPool2d(kernel_size=1, stride=1, padding=0),\n",
    "        nn.Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "        nn.BatchNorm2d(512),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.AvgPool2d(kernel_size=1, stride=1, padding=0),\n",
    "        nn.Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "        nn.BatchNorm2d(512),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.AvgPool2d(kernel_size=1, stride=1, padding=0),\n",
    "        nn.MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False),\n",
    "        nn.AvgPool2d(kernel_size=1, stride=1, padding=0),\n",
    "        nn.Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "        nn.BatchNorm2d(512),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.AvgPool2d(kernel_size=1, stride=1, padding=0),\n",
    "        nn.Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "        nn.BatchNorm2d(512),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.AvgPool2d(kernel_size=1, stride=1, padding=0),\n",
    "        nn.Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "        nn.BatchNorm2d(512),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.AvgPool2d(kernel_size=1, stride=1, padding=0),\n",
    "        nn.MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False),\n",
    "        nn.AvgPool2d(kernel_size=1, stride=1, padding=0),\n",
    "        )\n",
    "        self.fc_layer = nn.Sequential(\n",
    "            nn.Linear(512,10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # conv layers\n",
    "        x = self.conv_layer(x)\n",
    "        \n",
    "        # flatten\n",
    "        x = x.view(x.size(0), -1)\n",
    "        \n",
    "        # fc layer\n",
    "        x = self.fc_layer(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "def main():\n",
    "    # load and transform dataset\n",
    "    transform = transforms.Compose([\n",
    "        transforms.RandomCrop(32, padding=4),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "         transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "    trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                            download=True, transform=transform)\n",
    "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=128,\n",
    "                                              shuffle=True, num_workers=2)\n",
    "\n",
    "    testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                           download=True, transform=transform)\n",
    "    testloader = torch.utils.data.DataLoader(testset, batch_size=100,\n",
    "                                             shuffle=False, num_workers=2)\n",
    "\n",
    "    classes = ('plane', 'car', 'bird', 'cat',\n",
    "               'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "    # TODO: Define your optimizer and criterion.\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    model = CNN()\n",
    "    if train_on_gpu:\n",
    "        model.cuda()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=1e-1,\n",
    "                      momentum=0.9, weight_decay=5e-4)\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=200)\n",
    "\n",
    "    num_epoch = 200\n",
    "    for epoch in range(num_epoch):  # loop over the dataset multiple times\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs, labels = data\n",
    "            if train_on_gpu:\n",
    "                inputs, labels = inputs.cuda(), labels.cuda()\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "            if i % 2000 == 1999:  # print every 2000 mini-batches\n",
    "                print('[%d, %5d] loss: %.5f' %\n",
    "                      (epoch + 1, i + 1, running_loss / 2000))\n",
    "                running_loss = 0.0\n",
    "        print('Epoch = %d | loss = %.4f'%(epoch+1,running_loss/len(trainloader)))\n",
    "        scheduler.step()\n",
    "        accuracy(model,testloader)\n",
    "\n",
    "    print('Finished Training')\n",
    "\n",
    "    PATH = './model.pth'\n",
    "    torch.save(model.state_dict(), PATH)\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels = data\n",
    "            if train_on_gpu:\n",
    "                images, labels = images.cuda(), labels.cuda()\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "            100 * correct / total))\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
